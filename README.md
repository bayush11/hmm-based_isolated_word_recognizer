# hmm-based_isolated_word_recognizer

This is a HMM Based Isolated Word Recognizer. It contains 3 parts.

1. Sequence scoring using the Forward Algorithm
2. State-level decoding using the Viterbi algorithm
3. Maximum likelihood re-estimation of the transition matrix, using Viterbi training.

## MyHMM class description:

â€¢ N_states: An integer value representing the number of total states in the HMM
â€¢ pi: A 1-dimensional array of size N_states, where pi[i] = log ğœ‹ğ‘–
â€¢ A: A 2-dimensional array of size N_states by N_states representing the transition matrix, where A[i,j] = log ğ‘ğ‘–ğ‘—
â€¢ labels: A 1-dimensional array of size N_states, where labels[i] indicates the phonetic identity (class index) of state ğ‘–. This can be used to retrieve the phonetic label of the state via phone_labels[labels[i]], or to retrieve the observation likelihood ğ‘ğ‘– (ğ‘œğ‘¡ ) via L[t, labels[i]]

## Function Descriptions:

load_audio_to_mel_spec_tensor: This function takes as input the path to a .wav file, and returns a PyTorch tensor of size (N_frames, 40) representing the log Mel spectrogram of the .wav file, computed over 40 Mel filters.

compute_phone_likelihoods: This function takes as input a deep neural network acoustic model, as well as a PyTorch tensor containing the log Mel spectrogram computed with load_audio_to_melspec_tensor. The output will be a numpy array of shape (N_timesteps, 48), where the first dimension indexes acoustic frames and the second dimension indexes the log likelihoods across the 48 different phoneme classes.

forward: This function should compute ğ‘(ğ‘‚|ğœ†), where ğ‘‹ = ğ‘œ1, ğ‘œ2, ...ğ‘œğ‘ are the acoustic frames representing a speech waveform, and ğœ† are the acoustic model and HMM parameters. There are three steps.

1. Initialization: ğ›¼1(ğ‘–) = ğ‘ğ‘– (ğ‘œ1)ğœ‹ğ‘–
2. Induction: ğ›¼ğ‘¡+1(ğ‘–) = [âˆ‘ğ‘ ğ‘—=1 ğ›¼ğ‘¡ (ğ‘—)ğ‘ğ‘—ğ‘– ]ğ‘ğ‘– (ğ‘œğ‘¡+1)
3. Termination: ğ‘(ğ‘œ1, ..., ğ‘œğ‘‡ , ğ‘ğ‘‡ = ğ‘ ğ‘ |ğœ†) = ğ›¼ğ‘‡ (ğ‘ )

where

â€¢ ğ›¼ğ‘¡ (ğ‘–) represents the joint likelihood of having seen the observations up to time ğ‘¡ ğ‘œ1, ğ‘œ2, ..., ğ‘œğ‘¡ and being in state ğ‘– at time ğ‘¡.
â€¢ ğ‘ğ‘– (ğ‘œğ‘¡ ) is the likelihood of emitting observation ğ‘œğ‘¡ in state ğ‘–
â€¢ ğ‘ğ‘–ğ‘— is the probability of transitioning from state ğ‘– to state ğ‘—
â€¢ ğœ‹ğ‘– is the probability of being in state ğ‘– at time ğ‘¡ = 1
â€¢ ğ‘ğ‘‡ = ğ‘ ğ‘ indicates we are in state ğ‘ ğ‘ at time ğ‘‡

The output of the forward algorithm should be a log likelihood, representing log ğ‘(ğ‘œ1, ...ğ‘œğ‘‡ , ğ‘ğ‘‡ = ğ‘†ğ‘ |ğœ†) for a given input waveform and the current setting of the HMM parameters.

viterbi: The Viterbi algorithm is very similar to the Forward algorithm, with two notable differences. First, in the induction step, we replace the summation with a max. Second, we keep a backtrace matrix Î¨ that we can use to remember the best state at time ğ‘¡ âˆ’ 1 that transitioned to some given state at time ğ‘¡. It contains 4 steps:

1. Initialization: ğ›¿1(ğ‘–) = ğ‘ğ‘– (ğ‘œ1)ğœ‹ğ‘– , Î¨1(ğ‘–) = 0
2. Induction: ğ›¿ğ‘¡ (ğ‘–) = [maxğ‘— ğ›¿ğ‘¡âˆ’1(ğ‘—)ğ‘ğ‘—ğ‘– ]ğ‘ğ‘– (ğ‘œğ‘¡ ), Î¨ğ‘¡ (ğ‘–) = arg maxğ‘— ğ›¿ğ‘¡âˆ’1(ğ‘—)ğ‘ğ‘—ğ‘–
3. Termination: ğ‘â‹†ğ‘‡ = arg maxğ‘– ğ›¿ğ‘‡ (ğ‘–)
4. Backtrace: ğ‘â‹†ğ‘¡ = Î¨ğ‘¡+1(ğ‘â‹†ğ‘¡+1)

The output of the viterbi algorithm should be the best hidden state sequence for the input observation sequence.
